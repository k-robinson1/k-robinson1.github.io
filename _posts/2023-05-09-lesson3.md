# Lesson 3!
# Lesson 3!

Lesson 3 compared different architectures and also talked about gradient descent and loss functions.

Some key takeaways were:
- paperspace is an alternative to kaggle and colab and it offers free GPUs and makes it easy to save and load in files
- timm library contains all the different architectures
- Jeremy presented a really interesting graph comparing the speed and accuracy of all the different architectures. Was very easy to visualise and will definitely be using this to help choose suitable architectures for assignment 3 question 3!
- Jeremy said the biggest mistake students make is automatically choosing the most accurate model. Start with something small that is easy to play around with, and then only increase the model size as needed.
- The @interact tool is a useful way to manually tune hyperparameters
- Jeremy explained gradient descent really well! Increase the parameter if the gradient is negative and vice versa. The size of the gradient multiplied by the learning rate is how much the parameter should be increased / decreased. Doing this iteratively is the gradient descent method.
